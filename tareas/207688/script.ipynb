{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqQ9VK255g1T"
   },
   "source": [
    "# Tarea: Web Scraping con Selenium y Docker\n",
    "### Objetivo:\n",
    "\n",
    "Aprender a utilizar Selenium junto con Docker para realizar web scraping y extraer información de una página web. En esta tarea, extraerás los títulos de noticias de una página web de tu elección o la proporcionada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nR3PXYU55g1Y"
   },
   "source": [
    "## Código de Web Scraping\n",
    "\n",
    "A continuación, te proporciono un script en Python utilizando Selenium para obtener los títulos de noticias de una página web. En este caso, utilizaremos la página de noticias de \"https://news.ycombinator.com/\" como ejemplo.\n",
    "\n",
    "Tu debes completar el script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias necesarias para el funcionamiento del programa\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jT9RTIN-5g1Z"
   },
   "outputs": [],
   "source": [
    "# Configura las opciones de Chrome\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Ejecutar Chrome en modo headless (sin interfaz gráfica)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Conéctate al servidor Selenium Grid\n",
    "driver = webdriver.Remote(\n",
    "    command_executor=\"http://selenium-server:4444/wd/hub\",\n",
    "    options=chrome_options\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Abre la página de noticias\n",
    "    driver.get(\"https://news.ycombinator.com/\")\n",
    "\n",
    "    # Extrae los títulos de las noticias\n",
    "    titles = driver.find_elements(By.CLASS_NAME, \"titleline\")\n",
    "\n",
    "    # Imprime los títulos\n",
    "    print(\"\\nTítulos extraídos:\")\n",
    "    for idx, title in enumerate(titles, start=1):\n",
    "        print(f\"{idx}: {title.text}\")\n",
    "\n",
    "finally:\n",
    "    # Cierra el navegador\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-a4OeRmD5g1d"
   },
   "source": [
    "Descripción del Código:\n",
    "\n",
    "* Configuración de Selenium: Se configura Selenium con el navegador Chrome utilizando opciones específicas para ejecutarlo dentro de Docker.\n",
    "\n",
    "* Acceso a la Página Web: El script se conecta a la página de noticias de \"YCombinator\" y carga el contenido.\n",
    "\n",
    "* Extracción de Datos: Se utiliza find_elements con la clase storylink para obtener todos los títulos de las noticias en la página.\n",
    "\n",
    "* Impresión de Resultados: Los títulos extraídos se imprimen en la consola."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpiBtyhJ5g1e"
   },
   "source": [
    "### Ejercicio 2:\n",
    "\n",
    "* Buscar dentro de la página web alguno de los links de arriba (New, Past, etc) y ponerlo en un df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DAtHMw9j5g1f"
   },
   "outputs": [],
   "source": [
    "# Configura las opciones de Chrome\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Ejecutar Chrome en modo headless (sin interfaz gráfica)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Conéctate al servidor Selenium Grid\n",
    "driver = webdriver.Remote(\n",
    "    command_executor=\"http://selenium-server:4444/wd/hub\",\n",
    "    options=chrome_options\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Abre la página de noticias\n",
    "    driver.get(\"https://news.ycombinator.com/\")\n",
    "\n",
    "    # Encuentra los enlaces de navegación (clase `pagetop`)\n",
    "    nav_links = driver.find_elements(By.CSS_SELECTOR, \"td.title a\")\n",
    "\n",
    "    # Extrae los textos y URLs de los enlaces\n",
    "    links_data = []\n",
    "    for link in nav_links:\n",
    "        text = link.text\n",
    "        href = link.get_attribute(\"href\")\n",
    "        links_data.append({\"Texto\": text, \"URL\": href})\n",
    "\n",
    "    # Crear un DataFrame con los enlaces\n",
    "    df_links = pd.DataFrame(links_data)\n",
    "\n",
    "    # Mostrar el DataFrame\n",
    "    print(\"\\nEnlaces de navegación extraídos:\")\n",
    "    print(df_links)\n",
    "\n",
    "finally:\n",
    "    # Cierra el navegador\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqCexKsm5g1f"
   },
   "source": [
    "### Ejercicio 3:\n",
    "\n",
    "* Buscar algo dentro la pagina en el apartado de \"Search\" y ponerlo en un df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLjMjOQu5g1g"
   },
   "outputs": [],
   "source": [
    "# Configura las opciones de Chrome\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Ejecutar Chrome en modo headless (sin interfaz gráfica)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Conéctate al servidor Selenium Grid\n",
    "driver = webdriver.Remote(\n",
    "    command_executor=\"http://selenium-server:4444/wd/hub\",\n",
    "    options=chrome_options\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Abre la página de Hacker News\n",
    "    driver.get(\"https://news.ycombinator.com/\")\n",
    "\n",
    "    # Encuentra el enlace de búsqueda (Search) y haz clic\n",
    "    search_link = driver.find_element(By.LINK_TEXT, \"Search\")\n",
    "    search_link.click()\n",
    "\n",
    "    # Espera un momento para que la página de búsqueda cargue\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Encuentra el cuadro de búsqueda e ingresa el término de búsqueda\n",
    "    search_box = driver.find_element(By.NAME, \"q\")\n",
    "    search_term = \"data science\"\n",
    "    search_box.send_keys(search_term)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "    # Espera un momento para que los resultados carguen\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Encuentra los títulos de los resultados de la búsqueda\n",
    "    results = driver.find_elements(By.CSS_SELECTOR, \"a.storylink\")\n",
    "\n",
    "    # Extrae el texto y los enlaces de los resultados\n",
    "    search_results = []\n",
    "    for result in results:\n",
    "        title = result.text\n",
    "        link = result.get_attribute(\"href\")\n",
    "        search_results.append({\"Título\": title, \"URL\": link})\n",
    "\n",
    "    # Crea un DataFrame con los resultados\n",
    "    df_results = pd.DataFrame(search_results)\n",
    "\n",
    "    # Muestra el DataFrame\n",
    "    print(\"\\nResultados de la búsqueda:\")\n",
    "    print(df_results)\n",
    "\n",
    "finally:\n",
    "    # Cierra el navegador\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJ-Tauim5g1g"
   },
   "source": [
    "Ejecución del Script:\n",
    "    \n",
    "Para ejecutar el script, asegúrate de que los contenedores de Docker estén corriendo y luego ejecuta el siguiente comando en la terminal:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHFhFV4C5g1h"
   },
   "outputs": [],
   "source": [
    "docker-compose run --rm python python script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wyl7v4Yg5g1i"
   },
   "source": [
    "### ENTREGABLES:\n",
    "* script.py: El archivo con el código para realizar el web scraping y extraer los títulos de las noticias.\n",
    "* README.md: Instrucciones para ejecutar el proyecto."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
